{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "993c4538",
   "metadata": {},
   "source": [
    "–ú—ã—à–∫–æ–≤–µ—Ü –°.–ê., v.1 1.05.2023\n",
    "\n",
    "–†–µ—à–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏:\n",
    "\n",
    "–°—Ä–∞–≤–Ω–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ä–µ—à–µ–Ω–∏—è –ø–æ —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ —Ç–µ—Å—Ç–æ–≤.\n",
    "\n",
    "–í—ã–≤–æ–¥:\n",
    "\n",
    "–ü—Ä–∏ –æ—Ü–µ–Ω–∫–µ —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏  —Å—Ä–∞–≤–Ω–∏–≤–∞—é—Ç—Å—è –ø—Ä–µ–¥–∏–∫—Ç—ã —Å –∫—Ä–∞—Ç–∫–∏–º —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ–º, —Å–æ–∑–¥–∞–Ω–Ω—ã–º —á–µ–ª–æ–≤–µ–∫–æ–º. –ù–µ —Å–æ–≤—Å–µ–º –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å–Ω—ã–π –∫—Ä–∏—Ç–µ—Ä–∏–π.\n",
    "–ú–æ–¥–µ–ª—å facebook/bart-large-cnn –æ–±—É—á–µ–Ω–∞ –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ cnn daily –∏ —Ö–æ—Ä–æ—à–æ —Å–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è —Å —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–µ–π –Ω–æ–≤–æ—Å—Ç–µ–π.\n",
    "–ú–æ–¥–µ–ª—å philschmid/bart-large-cnn-samsum —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏ —Ç–∞ –∂–µ –º–æ–¥–µ–ª—å facebook/bart-large-cnn –¥–æ—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è  –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ samsum –∏ —Ö–æ—Ä–æ—à–æ —Å–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è —Å —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–µ–π –¥–∏–∞–ª–æ–≥–æ–≤.\n",
    "–û–±–µ –º–æ–¥–µ–ª–∏ –¥–µ–ª–∞—é—Ç extractive summarazation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7665f1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score\n",
    "\n",
    "import evaluate\n",
    "\n",
    "import seaborn as sns \n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import gc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36e04a6d",
   "metadata": {},
   "source": [
    "# Metric Card for ROUGE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aa606cd1",
   "metadata": {},
   "source": [
    "**Metric Description**\n",
    "ROUGE, or Recall-Oriented Understudy for Gisting Evaluation, is a set of metrics and a software package used for evaluating automatic summarization and machine translation software in natural language processing. The metrics compare an automatically produced summary or translation against a reference or a set of references (human-produced) summary or translation.\n",
    "\n",
    "Note that ROUGE is case insensitive, meaning that upper case letters are treated the same way as lower case letters.\n",
    "\n",
    "This metrics is a wrapper around the Google Research reimplementation of ROUGE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ac7b9658",
   "metadata": {},
   "source": [
    "https://huggingface.co/spaces/evaluate-metric/rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c39357d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install evaluate\n",
    "# !pip install rouge-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "554cd975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 1.0, 'rouge2': 1.0, 'rougeL': 1.0, 'rougeLsum': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –º–µ—Ç—Ä–∏–∫–∏ ROUGE\n",
    "rouge = evaluate.load('rouge')\n",
    "predictions = [\"hello there\", \"general kenobi\"]\n",
    "references = [\"hello there\", \"general kenobi\"]\n",
    "results = rouge.compute(predictions=predictions,\n",
    "                         references=references,\n",
    "                            tokenizer=lambda x: x.split())\n",
    "print(results)\n",
    "# {'rouge1': 1.0, 'rouge2': 1.0, 'rougeL': 1.0, 'rougeLsum': 1.0}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f65cfced",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3481a044",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "277cec1f",
   "metadata": {},
   "source": [
    "# MOST LIKES & MOST DOWNLOADS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "77a60211",
   "metadata": {},
   "source": [
    "# facebook/bart-large-cnn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6312d150",
   "metadata": {},
   "source": [
    "**Model description**\n",
    "BART is a transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. BART is pre-trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text.\n",
    "\n",
    "BART is particularly effective when fine-tuned for text generation (e.g. summarization, translation) but also works well for comprehension tasks (e.g. text classification, question answering). This particular checkpoint has been fine-tuned on CNN Daily Mail, a large collection of text-summary pairs.\n",
    "\n",
    "**Intended uses & limitations**\n",
    "You can use this model for text summarization."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d5a6a93",
   "metadata": {},
   "source": [
    "**Evaluation results**\n",
    "\n",
    "ROUGE-1 on cnn_dailymail self-reported 42.949\n",
    "\n",
    "ROUGE-2 on cnn_dailymail self-reported 20.815\n",
    "\n",
    "ROUGE-L on cnn_dailymail self-reported 30.619\n",
    "\n",
    "ROUGE-LSUM on cnn_dailymail self-reported 40.038 \n",
    "\n",
    "loss on cnn_dailymail self-reported 2.529\n",
    "\n",
    "gen_len on cnn_dailymail self-reported 78.587\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fe3fe4e4",
   "metadata": {},
   "source": [
    "–ü—Ä–µ–¥–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ loss:\n",
    "\n",
    "**criterion label_smoothed_cross_entropy**\n",
    "\n",
    "https://github.com/facebookresearch/fairseq/blob/main/examples/bart/README.summarization.md#4-fine-tuning-on-cnn-dm-summarization-task\n",
    "4) Fine-tuning on CNN-DM summarization task:\n",
    "Example fine-tuning CNN-DM\n",
    "\n",
    "TOTAL_NUM_UPDATES=20000  \n",
    "WARMUP_UPDATES=500      \n",
    "LR=3e-05\n",
    "MAX_TOKENS=2048\n",
    "UPDATE_FREQ=4\n",
    "BART_PATH=/path/to/bart/model.pt\n",
    "\n",
    "CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 fairseq-train cnn_dm-bin \\\n",
    "    --restore-file $BART_PATH \\\n",
    "    --max-tokens $MAX_TOKENS \\\n",
    "    --task translation \\\n",
    "    --source-lang source --target-lang target \\\n",
    "    --truncate-source \\\n",
    "    --layernorm-embedding \\\n",
    "    --share-all-embeddings \\\n",
    "    --share-decoder-input-output-embed \\\n",
    "    --reset-optimizer --reset-dataloader --reset-meters \\\n",
    "    --required-batch-size-multiple 1 \\\n",
    "    --arch bart_large \\\n",
    "    --criterion label_smoothed_cross_entropy \\\n",
    "    --label-smoothing 0.1 \\\n",
    "    --dropout 0.1 --attention-dropout 0.1 \\\n",
    "    --weight-decay 0.01 --optimizer adam --adam-betas \"(0.9, 0.999)\" --adam-eps 1e-08 \\\n",
    "    --clip-norm 0.1 \\\n",
    "    --lr-scheduler polynomial_decay --lr $LR --total-num-update $TOTAL_NUM_UPDATES --warmup-updates $WARMUP_UPDATES \\\n",
    "    --fp16 --update-freq $UPDATE_FREQ \\\n",
    "    --skip-invalid-size-inputs-valid-test \\\n",
    "    --find-unused-parameters;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db50304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7ae38df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer_facebook = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "507abaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTICLE_from_docs = \"\"\" New York (CNN)When Liana Barrientos was 23 years old, she got married in Westchester County, New York.\n",
    "A year later, she got married again in Westchester County, but to a different man and without divorcing her first husband.\n",
    "Only 18 days after that marriage, she got hitched yet again. Then, Barrientos declared \"I do\" five more times, sometimes only within two weeks of each other.\n",
    "In 2010, she married once more, this time in the Bronx. In an application for a marriage license, she stated it was her \"first and only\" marriage.\n",
    "Barrientos, now 39, is facing two criminal counts of \"offering a false instrument for filing in the first degree,\" referring to her false statements on the\n",
    "2010 marriage license application, according to court documents.\n",
    "Prosecutors said the marriages were part of an immigration scam.\n",
    "On Friday, she pleaded not guilty at State Supreme Court in the Bronx, according to her attorney, Christopher Wright, who declined to comment further.\n",
    "After leaving court, Barrientos was arrested and charged with theft of service and criminal trespass for allegedly sneaking into the New York subway through an emergency exit, said Detective\n",
    "Annette Markowski, a police spokeswoman. In total, Barrientos has been married 10 times, with nine of her marriages occurring between 1999 and 2002.\n",
    "All occurred either in Westchester County, Long Island, New Jersey or the Bronx. She is believed to still be married to four men, and at one time, she was married to eight men at once, prosecutors say.\n",
    "Prosecutors said the immigration scam involved some of her husbands, who filed for permanent residence status shortly after the marriages.\n",
    "Any divorces happened only after such filings were approved. It was unclear whether any of the men will be prosecuted.\n",
    "The case was referred to the Bronx District Attorney\\'s Office by Immigration and Customs Enforcement and the Department of Homeland Security\\'s\n",
    "Investigation Division. Seven of the men are from so-called \"red-flagged\" countries, including Egypt, Turkey, Georgia, Pakistan and Mali.\n",
    "Her eighth husband, Rashid Rajput, was deported in 2006 to his native Pakistan after an investigation by the Joint Terrorism Task Force.\n",
    "If convicted, Barrientos faces up to four years in prison.  Her next court appearance is scheduled for May 18.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4bbe32ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': 'Liana Barrientos, 39, is charged with two counts of \"offering a false instrument for filing in the first degree\" In total, she has been married 10 times, with nine of her marriages occurring between 1999 and 2002. She is believed to still be married to four men.'}]\n"
     ]
    }
   ],
   "source": [
    "print(summarizer_facebook(ARTICLE_from_docs, max_length=130, min_length=30, do_sample=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0a2ed3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTICLE_bbc_news = \"\"\"Residents of a tiny Swiss village have all been evacuated because of the risk of an imminent rockslide.\n",
    "\n",
    "Brienz's fewer than 100 villagers were given just 48 hours to pack what they could and abandon their homes.\n",
    "\n",
    "Even the dairy cows were loaded up for departure after geologists warned a rockfall was imminent.\n",
    "\n",
    "Two million cubic metres of rock is coming loose from the mountain above, and a rockslide could obliterate the village.\n",
    "\n",
    "The development has raised questions about the safety of some mountain communities, as global warming changes the alpine environment.\n",
    "\n",
    "Brienz, in the eastern canton of Graub√ºnden, is now empty.\n",
    "\n",
    "The village has been judged a geological risk for some time and is built on land that is subsiding down towards the valley, causing the church spire to lean and large cracks to appear in buildings.\n",
    "\n",
    "As the minutes ticked towards the deadline to leave, even Brienz's dairy cows were being taken to safety.\n",
    "\n",
    "The residents, some young, some old, families, farmers and professional couples, had two days to abandon their homes.\n",
    "\n",
    "They were asked earlier this week to evacuate the village by Friday evening.\n",
    "\n",
    "Switzerland's Alpine regions are especially sensitive to global warming - as the permafrost high in the mountains begins to thaw, the rock becomes more unstable.\n",
    "\n",
    "This particular mountain has always been unstable, but recently the rock has been shifting faster and faster.\n",
    "\n",
    "Days of heavy rain could bring two million cubic metres of loosened rock crashing down the mountainside onto the village, scientists warned.\n",
    "\n",
    "Now the villagers must wait, in temporary accommodation, for the rock to fall - and hope it misses their homes.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "dfc169c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_produced_summary_bbc_news = \"\"\"Residents of a tiny Swiss village have all been evacuated  within 48 hours due to the risk of an imminent rockslide. \n",
    "The residents must wait and hope their homes will not be destroyed by loosened rock crashing down the mountainside. \n",
    "The safety of mountain communities has been judged a geological risk for some time and is considered to be a global warming consequence.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "65571834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'Residents of Brienz, in the eastern canton of Graub√ºnden, were given just 48 hours to leave their homes. Two million cubic metres of rock is coming loose from the mountain above, and a rockslide could obliterate the village.'}]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer_facebook(ARTICLE_bbc_news, max_length=70, min_length=30, do_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "06921b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def prediction(summarizer):\n",
    "#     for i in summarizer():\n",
    "#      for k, v in i.items():\n",
    "#         return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37ababd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction(summarizer_facebook(ARTICLE_bbc_news))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "5eaf6632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.24242424242424246, 'rouge2': 0.0, 'rougeL': 0.14141414141414138, 'rougeLsum': 0.16161616161616163}\n"
     ]
    }
   ],
   "source": [
    "rouge = evaluate.load('rouge')\n",
    "predictions = [\"The village of Brienz in Graub√ºnden is built on land that is subsiding down towards the valley. Two million cubic metres of rock is coming loose from the mountain above and could obliterate the village.\"]\n",
    "# references = [\"Residents of a tiny Swiss village have all been evacuated  within 48 hours due to the risk of an imminent rockslide. The residents must wait and hope their homes will not be destroyed by loosened rock crashing down the mountainside. The safety of mountain communities has been judged a geological risk for some time and is considered to be a global warming consequence.\"]\n",
    "references = [human_produced_summary_bbc_news]\n",
    "results = rouge.compute(predictions=predictions,\n",
    "                        references=references,\n",
    "                        # tokenizer=lambda x: x.split()\n",
    "                            )\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4a7b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pretrained model - ValueError: No model config found in the file at .\n",
    "# Saved weights, no model architecture\n",
    "\n",
    "model = tf.keras.models.load_model('tf_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7ae24990",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTICLE_review= \"\"\"I feel I have to write to keep others from wasting their money. \n",
    "This book seems to have been written by a 7th grader with poor grammatical skills for her age! \n",
    "As another reviewer points out, there is a misspelling on the cover, and I believe there is at least one per chapter. \n",
    "For example, it was mentioned twice that she had a \"lean\" on her house. \n",
    "I was so distracted by the poor writing and weak plot, that I decided to read with a pencil in hand to mark all of the horrible grammar and spelling. \n",
    "Please don't waste your money. I too, believe that the good reviews must have been written by the author's relatives. I will not put much faith in the reviews from now on!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ec838218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': \"I was so distracted by the poor writing and weak plot, that I decided to read with a pencil in hand to mark all of the horrible grammar and spelling. I too, believe that the good reviews must have been written by the author's relatives. I will not put much faith in the reviews from now on!\"}]\n"
     ]
    }
   ],
   "source": [
    "print(summarizer_facebook(ARTICLE_review, \n",
    "                        #   max_length=70, \n",
    "                        #   min_length=1, \n",
    "                          do_sample=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "2e63399e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n"
     ]
    }
   ],
   "source": [
    "rouge = evaluate.load('rouge')\n",
    "predictions = [\"I was so distracted by the poor writing and weak plot, that I decided to read with a pencil in hand to mark all of the horrible grammar and spelling. I too, believe that the good reviews must have been written by the author's relatives. I will not put much faith in the reviews from now on!\"]\n",
    "references = [\"Awful beyond belief!\"]\n",
    "results = rouge.compute(predictions=predictions,\n",
    "                        references=references,\n",
    "                        # tokenizer=lambda x: x.split()\n",
    "                            )\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "0df8654b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTICLE_dialogue = \"\"\"Jane: Good morning, Doctor Rudra, how are you doing?\n",
    "\n",
    "Doctor Rudra: Good morning, Jane. I am doing well. And you?\n",
    "\n",
    "Jane: I‚Äôm great, thank you. This is my friend Leila. She is thinking about joining the hospital but she has a few questions about the administration there. Would you mind telling her about the administration, please?\n",
    "\n",
    "Doctor Rudra: Hello, Leila! It‚Äôs a pleasure to meet you. I‚Äôm more than happy to speak with you. Please stop by my chamber tomorrow.\n",
    "\n",
    "Leila: It‚Äôs a pleasure to meet you, Doctor. Thank you so much for helping us.\n",
    "\n",
    "Doctor Rudra: Don‚Äôt mention it. Hopefully, I will be able to help you out in this matter.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e6e5354b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': 'Jane: Good morning, Doctor Rudra, how are you doing? Rudra: I am doing well. Jane: I‚Äôm great, thank you. This is my friend Leila. She is thinking about joining the'}]\n"
     ]
    }
   ],
   "source": [
    "print(summarizer_facebook(ARTICLE_dialogue, max_length=50, min_length=30, do_sample=False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "844c5aca",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9ff1c86f",
   "metadata": {},
   "source": [
    "# philschmid/bart-large-cnn-samsum"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54ee4f49",
   "metadata": {},
   "source": [
    "**Evaluation results**\n",
    "\n",
    "eval_rouge1\t42.621\n",
    "\n",
    "eval_rouge2\t21.9825\n",
    "\n",
    "eval_rougeL\t33.034\n",
    "\n",
    "eval_rougeLsum\t39.6783\n",
    "\n",
    "test_rouge1\t41.3174\n",
    "\n",
    "test_rouge2\t20.8716\n",
    "\n",
    "test_rougeL\t32.1337\n",
    "\n",
    "test_rougeLsum\t38.4149"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "750d975f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "summarizer_philschmid= pipeline(\"summarization\", model=\"philschmid/bart-large-cnn-samsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "dc2417f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_from_docs = '''Jeff: Can I train a ü§ó Transformers model on Amazon SageMaker? \n",
    "Philipp: Sure you can use the new Hugging Face Deep Learning Container. \n",
    "Jeff: ok.\n",
    "Jeff: and how can I get started? \n",
    "Jeff: where can I find documentation? \n",
    "Philipp: ok, ok you can find everything here. https://huggingface.co/blog/the-partnership-amazon-sagemaker-and-hugging-face                                           \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a8acdedf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': \"Jeff wants to train a Transformers model on Amazon SageMaker. He can use the new Hugging Face Deep Learning Container. Jeff can find the documentation on Huggingface's blog.    .   The blog is available at: https://huggingface.co/blog/the-partnership-amazon-sagemaker-and-hugling-face.\"}]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer_philschmid(conversation_from_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "c5e6e13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_test = '''Waiter: Hello, good evening. Can I start you off with some refreshing drink?\n",
    "\n",
    "Rana: Yes. I‚Äôll have iced tea, please.\n",
    "\n",
    "Amal: And I‚Äôll have a chocolate cold coffee.\n",
    "\n",
    "Waiter: Ok. Should I take your order now, or do you need a few minutes more?\n",
    "\n",
    "Rana: No no we are ready, you can take the order. I‚Äôll have the corn mushroom soup to start, and the grilled chicken with mashed potatoes and peas. And, please also bring a bowl of garlic rice.\n",
    "\n",
    "Waiter: Sure sir. How do you want the chicken‚Äî low spicy, medium, or high on spice?\n",
    "\n",
    "Rana: Medium spice, please.\n",
    "\n",
    "Amal: And I‚Äôll just have the beef, with bread and a salad.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "cea6b924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': \"Waiter will take Rana's and Amal's order. Rana will have the corn mushroom soup, grilled chicken with mashed potatoes and peas and garlic rice. Amal will have beef, with bread, salad and a beef sandwich. She will also have a chocolate cold coffee.\"}]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer_philschmid(conversation_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "1463faf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTICLE_bbc_news = \"\"\"Residents of a tiny Swiss village have all been evacuated because of the risk of an imminent rockslide.\n",
    "\n",
    "Brienz's fewer than 100 villagers were given just 48 hours to pack what they could and abandon their homes.\n",
    "\n",
    "Even the dairy cows were loaded up for departure after geologists warned a rockfall was imminent.\n",
    "\n",
    "Two million cubic metres of rock is coming loose from the mountain above, and a rockslide could obliterate the village.\n",
    "\n",
    "The development has raised questions about the safety of some mountain communities, as global warming changes the alpine environment.\n",
    "\n",
    "Brienz, in the eastern canton of Graub√ºnden, is now empty.\n",
    "\n",
    "The village has been judged a geological risk for some time and is built on land that is subsiding down towards the valley, causing the church spire to lean and large cracks to appear in buildings.\n",
    "\n",
    "As the minutes ticked towards the deadline to leave, even Brienz's dairy cows were being taken to safety.\n",
    "\n",
    "The residents, some young, some old, families, farmers and professional couples, had two days to abandon their homes.\n",
    "\n",
    "They were asked earlier this week to evacuate the village by Friday evening.\n",
    "\n",
    "Switzerland's Alpine regions are especially sensitive to global warming - as the permafrost high in the mountains begins to thaw, the rock becomes more unstable.\n",
    "\n",
    "This particular mountain has always been unstable, but recently the rock has been shifting faster and faster.\n",
    "\n",
    "Days of heavy rain could bring two million cubic metres of loosened rock crashing down the mountainside onto the village, scientists warned.\n",
    "\n",
    "Now the villagers must wait, in temporary accommodation, for the rock to fall - and hope it misses their homes.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "e32ea3f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'The residents of Brienz, in the eastern canton of Graub√ºnden, Switzerland, were asked to leave their homes by Friday evening due to the risk of a rockslide. Two million cubic metres of loose rock is coming loose from the mountain and could obliterate the village. Even the dairy cows were loaded up for departure.'}]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer_philschmid(ARTICLE_bbc_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "bf648f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.38983050847457623, 'rouge2': 0.13793103448275862, 'rougeL': 0.22033898305084743, 'rougeLsum': 0.30508474576271183}\n"
     ]
    }
   ],
   "source": [
    "rouge = evaluate.load('rouge')\n",
    "predictions = [\"The residents of Brienz, in the eastern canton of Graub√ºnden, Switzerland, were asked to leave their homes by Friday evening due to the risk of a rockslide. Two million cubic metres of loose rock is coming loose from the mountain and could obliterate the village. Even the dairy cows were loaded up for departure.\"]\n",
    "references = [human_produced_summary_bbc_news]\n",
    "results = rouge.compute(predictions=predictions,\n",
    "                        references=references,\n",
    "                        # tokenizer=lambda x: x.split()\n",
    "                            )\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad17233",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTICLE_review= \"\"\"I feel I have to write to keep others from wasting their money. \n",
    "This book seems to have been written by a 7th grader with poor grammatical skills for her age! \n",
    "As another reviewer points out, there is a misspelling on the cover, and I believe there is at least one per chapter. \n",
    "For example, it was mentioned twice that she had a \"lean\" on her house. \n",
    "I was so distracted by the poor writing and weak plot, that I decided to read with a pencil in hand to mark all of the horrible grammar and spelling. \n",
    "Please don't waste your money. I too, believe that the good reviews must have been written by the author's relatives. I will not put much faith in the reviews from now on!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "4f066e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'The book seems to have been written by a 7th grader with poor grammatical skills for her age. There is a misspelling on the cover and there are at least one per chapter. I was so distracted by the poor writing and weak plot that I decided to read with a pencil in hand to mark all of the horrible grammar and spelling.'}]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer_philschmid(ARTICLE_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "c62e5d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n"
     ]
    }
   ],
   "source": [
    "rouge = evaluate.load('rouge')\n",
    "predictions = [\"The book seems to have been written by a 7th grader with poor grammatical skills for her age. There is a misspelling on the cover and there are at least one per chapter. I was so distracted by the poor writing and weak plot that I decided to read with a pencil in hand to mark all of the horrible grammar and spelling.\"]\n",
    "references = [\"Awful beyond belief!\"]\n",
    "results = rouge.compute(predictions=predictions,\n",
    "                        references=references,\n",
    "                        # tokenizer=lambda x: x.split()\n",
    "                            )\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90859a58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
